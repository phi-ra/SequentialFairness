{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "# metrics\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from main.utils.preprocessing import preprocess_census\n",
    "from main.estimators.evaluation import cv_early_stopping\n",
    "from main.fairness.metrics import unfairness, get_all_predictions, calculate_metrics\n",
    "from main.utils.dataloader import load_sunbelt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunbelt_states = ['AL', 'AZ', 'FL', 'GA', 'LA', \n",
    "                  'MS', 'NM', 'SC', 'TX', 'CA']\n",
    "\n",
    "data_all = load_sunbelt_data(states=sunbelt_states)\n",
    "\n",
    "cat_features = ['OCCP', 'POBP', 'SCHL', 'RELP']\n",
    "\n",
    "ret_dict =  preprocess_census(data=data_all,\n",
    "                              target_feature='PINCP',\n",
    "                              sensitive_features=['SEX', 'RAC1P_black'],\n",
    "                              categorical_features=cat_features,\n",
    "                              continuous_features=['WKHP', 'AGEP'], \n",
    "                              objective='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "res_dict['bench'] = {}\n",
    "res_dict['ours'] = {}\n",
    "\n",
    "for seed_ in [42, 1029, 3948, 103, 56, 93983838, 828, 1928838, 900, 10]:\n",
    "\n",
    "\n",
    "    sunbelt_states = ['AL', 'AZ', 'FL', 'GA', 'LA', \n",
    "                    'MS', 'NM', 'SC', 'TX', 'CA']\n",
    "\n",
    "    data_all = load_sunbelt_data(states=sunbelt_states)\n",
    "\n",
    "    cat_features = ['OCCP', 'POBP', 'SCHL', 'RELP']\n",
    "\n",
    "    ret_dict =  preprocess_census(data=data_all,\n",
    "                                target_feature='PINCP',\n",
    "                                sensitive_features=['SEX', 'RAC1P_black'],\n",
    "                                categorical_features=cat_features,\n",
    "                                continuous_features=['WKHP', 'AGEP'], \n",
    "                                objective='classification', \n",
    "                                split_seed=seed_)\n",
    "\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    cv_results = cv_early_stopping(params=params, \n",
    "                                nfolds=5, \n",
    "                                max_rounds=1000, \n",
    "                                early_stopping_rounds=20, \n",
    "                                X_train=ret_dict['X_train'], \n",
    "                                y_train=ret_dict['y_train'], \n",
    "                                categorical_feats=cat_features, \n",
    "                                objective='classification')\n",
    "\n",
    "\n",
    "    best_res = np.argmax(cv_results['metric'])\n",
    "    best_iter = cv_results['iterations'][best_res]\n",
    "\n",
    "    # Retrain whole model\n",
    "\n",
    "    start_ours = time.time()\n",
    "\n",
    "    data_train_all = lgb.Dataset(data=ret_dict['X_train'], \n",
    "                                label=ret_dict['y_train'], \n",
    "                                categorical_feature=cat_features)\n",
    "\n",
    "    best_estimator = lgb.train(params=params,\n",
    "                            train_set=data_train_all, \n",
    "                            num_boost_round=best_iter)\n",
    "\n",
    "\n",
    "    output_check = get_all_predictions(best_estimator, \n",
    "                                    ['SEX_2', 'RAC1P_black'], \n",
    "                                    ret_dict)\n",
    "\n",
    "\n",
    "    end_ours = time.time()\n",
    "\n",
    "    time_ours = end_ours - start_ours\n",
    "\n",
    "\n",
    "    ret_metrics = calculate_metrics(output_check, \n",
    "                    ret_dict['y_test'], \n",
    "                    objective='classification', \n",
    "                    threshold=0.48)\n",
    "\n",
    "    accuracy_ours_0 = ret_metrics[('SEX_2', 'RAC1P_black')]['level_0']['accuracy']\n",
    "    f1_ours_0 = ret_metrics[('SEX_2', 'RAC1P_black')]['level_0']['f1_score']\n",
    "\n",
    "    accuracy_ours_1 = ret_metrics[('SEX_2', 'RAC1P_black')]['level_1']['accuracy']\n",
    "    f1_ours_1 = ret_metrics[('SEX_2', 'RAC1P_black')]['level_1']['f1_score']\n",
    "\n",
    "    preds_level_0 = output_check[('SEX_2', 'RAC1P_black')]['level_0']['prediction']\n",
    "    preds_level_0 = np.where(preds_level_0 > 0.48, 1, 0)\n",
    "\n",
    "    preds_level_1 = output_check[('SEX_2', 'RAC1P_black')]['level_1']['prediction']\n",
    "    preds_level_1 = np.where(preds_level_1 > 0.48, 1, 0)\n",
    "\n",
    "    fairness_ours_0 = demographic_parity_difference(ret_dict['y_test'],\n",
    "                              preds_level_0, \n",
    "                              sensitive_features=ret_dict['X_test'].SEX_2)\n",
    "\n",
    "    fairness_ours_1 = (demographic_parity_difference(ret_dict['y_test'],\n",
    "                                preds_level_1, \n",
    "                                sensitive_features=ret_dict['X_test'].RAC1P_black) + \n",
    "                    demographic_parity_difference(ret_dict['y_test'],\n",
    "                                preds_level_1, \n",
    "                                sensitive_features=ret_dict['X_test'].SEX_2))    \n",
    "\n",
    "\n",
    "    # Benchmark \n",
    "\n",
    "    time_start_theirs = time.time()\n",
    "\n",
    "    # specify separately the boosting iterations, as otherwise \n",
    "    # the calculations would be prohibitively long...\n",
    "    classifier_lgbm = lgb.LGBMClassifier(metric='auc', \n",
    "                                        min_data_in_leaf='50',\n",
    "                                        learning_rate=0.05,\n",
    "                                        feature_fraction=0.9,\n",
    "                                        num_iterations=best_iter)\n",
    "\n",
    "    constraint = DemographicParity()\n",
    "    classifier = classifier_lgbm\n",
    "    mitigator = ExponentiatedGradient(classifier_lgbm,\n",
    "                                      constraint,\n",
    "                                      max_iter=5)\n",
    "\n",
    "    mitigator.fit(ret_dict['X_train'],\n",
    "                ret_dict['y_train'],\n",
    "                sensitive_features=ret_dict['X_train'].SEX_2)\n",
    "\n",
    "    \n",
    "    y_pred_mitigated = mitigator.predict(ret_dict['X_test'])\n",
    "\n",
    "    end_time_theirs = time.time()\n",
    "    \n",
    "    time_theirs = end_time_theirs - time_start_theirs\n",
    "\n",
    "\n",
    "    fairness_theirs_0 = demographic_parity_difference(ret_dict['y_test'],\n",
    "                              y_pred_mitigated, \n",
    "                              sensitive_features=ret_dict['X_test'].SEX_2)\n",
    "\n",
    "    fairness_theirs_1 = (demographic_parity_difference(ret_dict['y_test'],\n",
    "                                y_pred_mitigated, \n",
    "                                sensitive_features=ret_dict['X_test'].RAC1P_black) + \n",
    "                        demographic_parity_difference(ret_dict['y_test'],\n",
    "                                    y_pred_mitigated, \n",
    "                                    sensitive_features=ret_dict['X_test'].SEX_2))\n",
    "\n",
    "\n",
    "    accuracy_theirs = accuracy_score(ret_dict['y_test'],\n",
    "                                    y_pred_mitigated)\n",
    "\n",
    "    f1_theris = f1_score(ret_dict['y_test'],\n",
    "                         y_pred_mitigated)\n",
    "\n",
    "\n",
    "    res_dict['bench'][seed_] = {}\n",
    "    res_dict['ours'][seed_] = {}\n",
    "\n",
    "    res_dict['bench'][seed_]['acc'] = accuracy_theirs\n",
    "    res_dict['bench'][seed_]['f1'] = f1_theris\n",
    "    res_dict['bench'][seed_]['unfair'] = fairness_theirs_0\n",
    "\n",
    "    res_dict['bench'][seed_]['acc_1'] = accuracy_theirs\n",
    "    res_dict['bench'][seed_]['f1_1'] = f1_theris\n",
    "    res_dict['bench'][seed_]['unfair_1'] = fairness_theirs_1\n",
    "\n",
    "    # Time\n",
    "    res_dict['bench'][seed_]['time'] = time_theirs\n",
    "\n",
    "    # Metrics 0\n",
    "    res_dict['ours'][seed_]['acc'] = accuracy_ours_0\n",
    "    res_dict['ours'][seed_]['f1'] = f1_ours_0\n",
    "    res_dict['ours'][seed_]['unfair'] = fairness_ours_0\n",
    "\n",
    "    # Metrics 1\n",
    "    res_dict['ours'][seed_]['acc_1'] = accuracy_ours_1\n",
    "    res_dict['ours'][seed_]['f1_1'] = f1_ours_1\n",
    "    res_dict['ours'][seed_]['unfair_1'] = fairness_ours_1\n",
    "\n",
    "    # Time\n",
    "    res_dict['ours'][seed_]['time'] = time_ours\n",
    "\n",
    "    with open(f'data/results/output_bivariate_after_seed_{seed_}.pkl', 'wb') as con_:\n",
    "        pickle.dump(res_dict, con_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " &0.809 $\\pm$ 0.001  & 0.808  $\\pm$ 0.001 \\\\\n",
      " &0.737 $\\pm$ 0.001  & 0.73  $\\pm$ 0.002 \\\\\n",
      " &0.003 $\\pm$ 0.002  & 0.021  $\\pm$ 0.002 \\\\\n",
      " &0.804 $\\pm$ 0.001  & 0.808  $\\pm$ 0.001 \\\\\n",
      " &0.73 $\\pm$ 0.001  & 0.73  $\\pm$ 0.002 \\\\\n",
      " &0.009 $\\pm$ 0.005  & 0.207  $\\pm$ 0.005 \\\\\n",
      " &6.319 $\\pm$ 0.422  & 100.893  $\\pm$ 10.467 \\\\\n"
     ]
    }
   ],
   "source": [
    "for idx_ in range(pd.DataFrame(res_dict['ours']).shape[0]):\n",
    "    \n",
    "    ours_m = pd.DataFrame(res_dict['ours']).iloc[idx_, :].mean()\n",
    "    ours_s = pd.DataFrame(res_dict['ours']).iloc[idx_, :].std()\n",
    "\n",
    "    theirs_m = pd.DataFrame(res_dict['bench']).iloc[idx_, :].mean()\n",
    "    theirs_s = pd.DataFrame(res_dict['bench']).iloc[idx_, :].std()\n",
    "\n",
    "    print(f' &{np.round(ours_m,3)} $\\pm$ {np.round(ours_s,3)}  & {np.round(theirs_m,3)}  $\\pm$ {np.round(theirs_s,3)} \\\\\\\\')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cenv_sequential",
   "language": "python",
   "name": "cenv_sequential"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
